{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7712b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import numpy as np\n",
    "from RESNET50 import Bottleneck, ResNet, ResNet50\n",
    "\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(f\"Current directory: {current_directory}\")\n",
    "\n",
    "# Change the current working directory\n",
    "new_directory = r\"C:\\TCC\"  # Replace with your desired path\n",
    "os.chdir(new_directory)\n",
    "\n",
    "# Get the new working directory\n",
    "new_current_directory = os.getcwd()\n",
    "print(f\"New directory: {new_current_directory}\")\n",
    "\n",
    "\n",
    "from transform_data import trans_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOC=20\n",
    "LR=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389eb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = r\"C:\\Users\\joaog\\Deep_Learning\\Dataset\\chest_xray\\train\"\n",
    "test_data_path = r\"C:\\Users\\joaog\\Deep_Learning\\Dataset\\chest_xray\\test\"\n",
    "trainloader,testloader = trans_data(train_data_path,test_data_path,5216,36)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782ef9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNet50(10).to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "EPOCHS = EPOC\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    for i, inp in enumerate(trainloader):\n",
    "        inputs, labels = inp\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%9 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', round(running_loss / 100,5))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eda34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- Ensure your network is in evaluation mode ---\n",
    "net.eval()\n",
    "\n",
    "# --- Lists to store true labels and predictions ---\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "# --- No gradient calculation needed for inference ---\n",
    "with torch.no_grad():\n",
    "    # Iterate over the test data\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        # Get the predicted class (the one with the highest score)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Append batch predictions and labels to the lists\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# --- Get the class names from the dataset ---\n",
    "class_names = ['plane', 'car']\n",
    "\n",
    "# --- Compute the confusion matrix ---\n",
    "cm = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "# --- Plot the confusion matrix using seaborn ---\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix for CIFAR-10 Test Set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336b8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy on 10,000 test images: ', 100*(correct/total), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522ebbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Get one batch of test data\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    # Important: unnormalize if you normalized your data!\n",
    "    # This assumes you normalized with mean=0.5, std=0.5\n",
    "    img = img / 2 + 0.5     \n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# --- RUN THIS BLOCK ---\n",
    "# Show the first 4 images from the batch\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# Print the labels for those 4 images\n",
    "print(\"Labels for the images above: \", ' '.join(f'{labels[j].item()}' for j in range(4)))\n",
    "# --- --- --- --- --- --\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
